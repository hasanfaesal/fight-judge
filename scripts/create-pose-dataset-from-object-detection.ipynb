{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 13631800,
          "sourceType": "datasetVersion",
          "datasetId": 8664438
        }
      ],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "fight-judge-dataset-pose-created",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "7cdtn82eJlqs"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "hasanfaisal_mma_fighter_detection_pose_estimation_path = kagglehub.dataset_download('hasanfaisal/mma-fighter-detection-pose-estimation')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ffuF6P6pJlqw"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "   # for filename in filenames:\n",
        "        # print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T19:52:31.844635Z",
          "iopub.execute_input": "2025-11-07T19:52:31.845112Z",
          "iopub.status.idle": "2025-11-07T19:52:31.848915Z",
          "shell.execute_reply.started": "2025-11-07T19:52:31.845086Z",
          "shell.execute_reply": "2025-11-07T19:52:31.848202Z"
        },
        "id": "qWtnZIylJlqx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:06.884252Z",
          "iopub.execute_input": "2025-11-07T20:34:06.884767Z",
          "iopub.status.idle": "2025-11-07T20:34:10.162951Z",
          "shell.execute_reply.started": "2025-11-07T20:34:06.884743Z",
          "shell.execute_reply": "2025-11-07T20:34:10.162173Z"
        },
        "id": "g3baGp8BJlqy",
        "outputId": "a7cb69cd-d945-44da-b184-8815d30cb569"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.226)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.6)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.3)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.5)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.1.0)\nRequirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.25.0)\nRequirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.18)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "YOLO-Pose Keypoint Annotation Generator with GPU Acceleration (Kaggle Version)\n",
        "This script adds keypoint annotations to an existing YOLO detection dataset\n",
        "by using a pretrained pose estimation model, optimized for GPU processing.\n",
        "\n",
        "KAGGLE-SPECIFIC: Reads from /kaggle/input/ and writes to /kaggle/working/\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from tqdm.notebook import tqdm\n",
        "import shutil\n",
        "import torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:12.615817Z",
          "iopub.execute_input": "2025-11-07T20:34:12.616485Z",
          "iopub.status.idle": "2025-11-07T20:34:12.620679Z",
          "shell.execute_reply.started": "2025-11-07T20:34:12.616457Z",
          "shell.execute_reply": "2025-11-07T20:34:12.620035Z"
        },
        "id": "PQorCX7lJlq0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Path to your INPUT dataset (read-only on Kaggle)\n",
        "DATASET_INPUT = \"/kaggle/input/mma-fighter-detection-pose-estimation/mma-fighter-detection-dataset\"\n",
        "\n",
        "# Path to OUTPUT dataset (will be created in /kaggle/working/)\n",
        "DATASET_OUTPUT = \"/kaggle/working/mma-fighter-pose-dataset\"\n",
        "\n",
        "# Which splits to process (you can comment out splits you don't want to process)\n",
        "SPLITS = ['train', 'valid', 'test']\n",
        "\n",
        "# IoU threshold for matching pose detections to your fighter bounding boxes\n",
        "# Higher values mean stricter matching (0.3-0.5 is typically good)\n",
        "IOU_THRESHOLD = 0.6\n",
        "\n",
        "# Confidence threshold for pose detections\n",
        "# Lower this if the model misses fighters, raise it if you get false detections\n",
        "POSE_CONFIDENCE = 0.3\n",
        "\n",
        "# GPU Configuration\n",
        "# Set to None to auto-detect, or specify device like 'cuda:0', 'cuda:1', etc.\n",
        "DEVICE = None  # Will auto-select best available device\n",
        "\n",
        "# Batch size for GPU processing (higher = faster but uses more memory)\n",
        "# Start with 8 and increase if you have GPU memory to spare\n",
        "# Reduce to 4 or 2 if you get out-of-memory errors\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:17.584058Z",
          "iopub.execute_input": "2025-11-07T20:34:17.584328Z",
          "iopub.status.idle": "2025-11-07T20:34:17.588757Z",
          "shell.execute_reply.started": "2025-11-07T20:34:17.58431Z",
          "shell.execute_reply": "2025-11-07T20:34:17.588137Z"
        },
        "id": "wo7uVwzfJlq0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_device(device=None):\n",
        "    \"\"\"\n",
        "    Set up and verify GPU device for processing.\n",
        "\n",
        "    This function checks what compute devices are available on your system,\n",
        "    provides detailed information about GPU capabilities, and sets up the\n",
        "    optimal device for pose estimation processing.\n",
        "\n",
        "    Returns:\n",
        "        str: Device string ('cuda:0', 'cpu', etc.)\n",
        "        dict: Device information for logging\n",
        "    \"\"\"\n",
        "    device_info = {}\n",
        "\n",
        "    # Check if CUDA (NVIDIA GPU support) is available\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    device_info['cuda_available'] = cuda_available\n",
        "\n",
        "    if cuda_available:\n",
        "        # Get GPU count and details\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        device_info['gpu_count'] = gpu_count\n",
        "\n",
        "        # If no device specified, use GPU 0\n",
        "        if device is None:\n",
        "            device = 'cuda:0'\n",
        "\n",
        "        # Get information about the selected GPU\n",
        "        gpu_id = int(device.split(':')[1]) if ':' in device else 0\n",
        "        device_info['gpu_name'] = torch.cuda.get_device_name(gpu_id)\n",
        "        device_info['gpu_memory_total'] = torch.cuda.get_device_properties(gpu_id).total_memory / 1024**3  # GB\n",
        "\n",
        "        # Get current memory usage\n",
        "        torch.cuda.reset_peak_memory_stats(gpu_id)\n",
        "        device_info['gpu_memory_allocated'] = torch.cuda.memory_allocated(gpu_id) / 1024**3  # GB\n",
        "\n",
        "    else:\n",
        "        # No GPU available, fall back to CPU\n",
        "        if device is None or device.startswith('cuda'):\n",
        "            print(\"⚠ Warning: CUDA not available. Falling back to CPU.\")\n",
        "            print(\"  GPU processing will NOT be used. This will be significantly slower.\")\n",
        "            print(\"  To enable GPU: In Kaggle, go to Settings → Accelerator → Select 'GPU T4 x2'\")\n",
        "            device = 'cpu'\n",
        "        device_info['gpu_name'] = 'CPU'\n",
        "\n",
        "    device_info['device'] = device\n",
        "    return device, device_info\n",
        "\n",
        "\n",
        "def print_device_info(device_info):\n",
        "    \"\"\"Print detailed information about the compute device being used.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"COMPUTE DEVICE INFORMATION\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    if device_info['cuda_available']:\n",
        "        print(f\"✓ GPU acceleration ENABLED\")\n",
        "        print(f\"  Device: {device_info['device']}\")\n",
        "        print(f\"  GPU Name: {device_info['gpu_name']}\")\n",
        "        print(f\"  Total GPU Memory: {device_info['gpu_memory_total']:.2f} GB\")\n",
        "        print(f\"  Available GPUs: {device_info['gpu_count']}\")\n",
        "        print(f\"\\n  This will provide 10-50x speedup compared to CPU processing!\")\n",
        "    else:\n",
        "        print(f\"✗ GPU acceleration DISABLED\")\n",
        "        print(f\"  Device: {device_info['device']}\")\n",
        "        print(f\"  Processing will be done on CPU (much slower)\")\n",
        "\n",
        "    print(\"=\" * 70)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:19.264786Z",
          "iopub.execute_input": "2025-11-07T20:34:19.265315Z",
          "iopub.status.idle": "2025-11-07T20:34:19.27297Z",
          "shell.execute_reply.started": "2025-11-07T20:34:19.265288Z",
          "shell.execute_reply": "2025-11-07T20:34:19.272233Z"
        },
        "id": "v7Q6r7imJlq1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "setup_device()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:21.98653Z",
          "iopub.execute_input": "2025-11-07T20:34:21.987087Z",
          "iopub.status.idle": "2025-11-07T20:34:21.992389Z",
          "shell.execute_reply.started": "2025-11-07T20:34:21.987067Z",
          "shell.execute_reply": "2025-11-07T20:34:21.991631Z"
        },
        "id": "AOasSeP9Jlq2",
        "outputId": "40333a2f-4e70-470e-ac64-b67cc3b844b4"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "('cuda:0',\n {'cuda_available': True,\n  'gpu_count': 1,\n  'gpu_name': 'Tesla P100-PCIE-16GB',\n  'gpu_memory_total': 15.887939453125,\n  'gpu_memory_allocated': 0.0,\n  'device': 'cuda:0'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print_device_info({'cuda_available': True,\n",
        "  'gpu_count': 1,\n",
        "  'gpu_name': 'Tesla P100-PCIE-16GB',\n",
        "  'gpu_memory_total': 15.887939453125,\n",
        "  'gpu_memory_allocated': 0.0,\n",
        "  'device': 'cuda:0'})\n",
        "\n",
        "# this guy won't be able to take my job, incredibly stupid piece of code above"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:23.015146Z",
          "iopub.execute_input": "2025-11-07T20:34:23.015449Z",
          "iopub.status.idle": "2025-11-07T20:34:23.019943Z",
          "shell.execute_reply.started": "2025-11-07T20:34:23.015394Z",
          "shell.execute_reply": "2025-11-07T20:34:23.019103Z"
        },
        "id": "07fidlv2Jlq3",
        "outputId": "74dec888-75a4-46a6-b3d7-5d3632e079c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n======================================================================\nCOMPUTE DEVICE INFORMATION\n======================================================================\n✓ GPU acceleration ENABLED\n  Device: cuda:0\n  GPU Name: Tesla P100-PCIE-16GB\n  Total GPU Memory: 15.89 GB\n  Available GPUs: 1\n\n  This will provide 10-50x speedup compared to CPU processing!\n======================================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Calculate Intersection over Union between two bounding boxes.\n",
        "\n",
        "    Boxes are in YOLO format: [x_center, y_center, width, height] (normalized 0-1)\n",
        "\n",
        "    This function converts them to corner coordinates, calculates the\n",
        "    intersection area, and divides by the union area.\n",
        "    \"\"\"\n",
        "    # Convert from center format to corner format\n",
        "    box1_x1 = box1[0] - box1[2] / 2\n",
        "    box1_y1 = box1[1] - box1[3] / 2\n",
        "    box1_x2 = box1[0] + box1[2] / 2\n",
        "    box1_y2 = box1[1] + box1[3] / 2\n",
        "\n",
        "    box2_x1 = box2[0] - box2[2] / 2\n",
        "    box2_y1 = box2[1] - box2[3] / 2\n",
        "    box2_x2 = box2[0] + box2[2] / 2\n",
        "    box2_y2 = box2[1] + box2[3] / 2\n",
        "\n",
        "    # Calculate intersection area\n",
        "    inter_x1 = max(box1_x1, box2_x1)\n",
        "    inter_y1 = max(box1_y1, box2_y1)\n",
        "    inter_x2 = min(box1_x2, box2_x2)\n",
        "    inter_y2 = min(box1_y2, box2_y2)\n",
        "\n",
        "    # If boxes don't overlap, intersection is zero\n",
        "    if inter_x2 < inter_x1 or inter_y2 < inter_y1:\n",
        "        return 0.0\n",
        "\n",
        "    inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)\n",
        "\n",
        "    # Calculate union area\n",
        "    box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)\n",
        "    box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if union_area == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return inter_area / union_area"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:25.500916Z",
          "iopub.execute_input": "2025-11-07T20:34:25.501175Z",
          "iopub.status.idle": "2025-11-07T20:34:25.507302Z",
          "shell.execute_reply.started": "2025-11-07T20:34:25.501156Z",
          "shell.execute_reply": "2025-11-07T20:34:25.506639Z"
        },
        "id": "cSTQO_bfJlq4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def xyxy_to_xywh_normalized(box, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Convert bounding box from corner coordinates (x1, y1, x2, y2) in pixels\n",
        "    to YOLO format (x_center, y_center, width, height) normalized to 0-1.\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = box\n",
        "    x_center = ((x1 + x2) / 2) / img_width\n",
        "    y_center = ((y1 + y2) / 2) / img_height\n",
        "    width = (x2 - x1) / img_width\n",
        "    height = (y2 - y1) / img_height\n",
        "    return [x_center, y_center, width, height]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:28.940912Z",
          "iopub.execute_input": "2025-11-07T20:34:28.941218Z",
          "iopub.status.idle": "2025-11-07T20:34:28.946092Z",
          "shell.execute_reply.started": "2025-11-07T20:34:28.941195Z",
          "shell.execute_reply": "2025-11-07T20:34:28.945316Z"
        },
        "id": "F7NeMlMKJlq5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_existing_labels(label_path):\n",
        "    \"\"\"\n",
        "    Load existing bounding box annotations from a YOLO format label file.\n",
        "\n",
        "    Returns a list of [class_id, x_center, y_center, width, height] for each object.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(label_path):\n",
        "        return []\n",
        "\n",
        "    labels = []\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:  # class_id + 4 bbox coordinates\n",
        "                # Convert to floats\n",
        "                label = [int(parts[0])] + [float(x) for x in parts[1:5]]\n",
        "                labels.append(label)\n",
        "    return labels"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:39.875856Z",
          "iopub.execute_input": "2025-11-07T20:34:39.87655Z",
          "iopub.status.idle": "2025-11-07T20:34:39.881128Z",
          "shell.execute_reply.started": "2025-11-07T20:34:39.876525Z",
          "shell.execute_reply": "2025-11-07T20:34:39.880492Z"
        },
        "id": "tTGpXFaXJlq6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def save_yolo_pose_labels(label_path, annotations):\n",
        "    \"\"\"\n",
        "    Save annotations in YOLO-Pose format.\n",
        "\n",
        "    Format: class_id x_center y_center width height kp1_x kp1_y kp1_v ... kp17_x kp17_y kp17_v\n",
        "\n",
        "    Where each keypoint has x, y coordinates (normalized 0-1) and visibility flag v:\n",
        "    - 0: not labeled\n",
        "    - 1: labeled but not visible (occluded)\n",
        "    - 2: labeled and visible\n",
        "    \"\"\"\n",
        "    # Ensure directory exists\n",
        "    os.makedirs(os.path.dirname(label_path), exist_ok=True)\n",
        "\n",
        "    with open(label_path, 'w') as f:\n",
        "        for ann in annotations:\n",
        "            # Write class and bounding box\n",
        "            line = f\"{ann['class_id']} {ann['bbox'][0]:.6f} {ann['bbox'][1]:.6f} {ann['bbox'][2]:.6f} {ann['bbox'][3]:.6f}\"\n",
        "\n",
        "            # Write keypoints if they exist\n",
        "            if 'keypoints' in ann and ann['keypoints'] is not None:\n",
        "                for kp in ann['keypoints']:\n",
        "                    line += f\" {kp[0]:.6f} {kp[1]:.6f} {int(kp[2])}\"\n",
        "\n",
        "            f.write(line + '\\n')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:34:42.408539Z",
          "iopub.execute_input": "2025-11-07T20:34:42.409083Z",
          "iopub.status.idle": "2025-11-07T20:34:42.413916Z",
          "shell.execute_reply.started": "2025-11-07T20:34:42.409061Z",
          "shell.execute_reply": "2025-11-07T20:34:42.413194Z"
        },
        "id": "BpnWUDUPJlq6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MAIN PROCESSING FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def process_dataset(input_root, output_root, splits, iou_threshold, pose_confidence, device_str, batch_size):\n",
        "    \"\"\"\n",
        "    Main function that processes the entire dataset and adds keypoint annotations.\n",
        "\n",
        "    This version reads from a read-only input directory (Kaggle input) and writes\n",
        "    to a new output directory (Kaggle working).\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"YOLO-Pose Keypoint Annotation Generator (Kaggle Version)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nInput dataset: {input_root}\")\n",
        "    print(f\"Output dataset: {output_root}\")\n",
        "    print(f\"Splits to process: {splits}\")\n",
        "    print(f\"IoU threshold: {iou_threshold}\")\n",
        "    print(f\"Pose confidence: {pose_confidence}\")\n",
        "    print(f\"Batch size: {batch_size}\\n\")\n",
        "\n",
        "    # Setup GPU device\n",
        "    device, device_info = setup_device(device_str)\n",
        "    print_device_info(device_info)\n",
        "\n",
        "    # Load the pretrained YOLO-Pose model\n",
        "    # Using yolov8m-pose as a good balance between speed and accuracy\n",
        "    # You can also use: yolov8n-pose (faster), yolov8l-pose (more accurate), yolov8x-pose (most accurate)\n",
        "\n",
        "    # going to use yolov11x now! - hasan\n",
        "\n",
        "    print(\"\\nLoading pretrained YOLO-Pose model...\")\n",
        "    model = YOLO('yolo11x-pose.pt')\n",
        "\n",
        "    # Explicitly move model to the specified device\n",
        "    model.to(device)\n",
        "\n",
        "    print(f\"✓ Model loaded successfully on {device}!\\n\")\n",
        "\n",
        "    # Create output directory structure\n",
        "    os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "    # Copy data.yaml if it exists\n",
        "    yaml_src = os.path.join(input_root, 'data.yaml')\n",
        "    if os.path.exists(yaml_src):\n",
        "        yaml_dst = os.path.join(output_root, 'data.yaml')\n",
        "        print(f\"Copying data.yaml to output directory...\")\n",
        "        shutil.copy2(yaml_src, yaml_dst)\n",
        "        print(\"✓ data.yaml copied\\n\")\n",
        "\n",
        "    # Statistics tracking\n",
        "    stats = {\n",
        "        'total_images': 0,\n",
        "        'images_with_poses': 0,\n",
        "        'total_fighters_annotated': 0,\n",
        "        'fighters_matched': 0,\n",
        "        'fighters_unmatched': 0\n",
        "    }\n",
        "\n",
        "    # Process each split\n",
        "    for split in splits:\n",
        "        print(f\"\\n{'=' * 70}\")\n",
        "        print(f\"Processing {split.upper()} split\")\n",
        "        print(f\"{'=' * 70}\\n\")\n",
        "\n",
        "        input_images_dir = os.path.join(input_root, split, 'images')\n",
        "        input_labels_dir = os.path.join(input_root, split, 'labels')\n",
        "\n",
        "        output_images_dir = os.path.join(output_root, split, 'images')\n",
        "        output_labels_dir = os.path.join(output_root, split, 'labels')\n",
        "\n",
        "        if not os.path.exists(input_images_dir):\n",
        "            print(f\"⚠ Warning: {input_images_dir} does not exist. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Create output directories\n",
        "        os.makedirs(output_images_dir, exist_ok=True)\n",
        "        os.makedirs(output_labels_dir, exist_ok=True)\n",
        "\n",
        "        # Get all image files\n",
        "        image_files = []\n",
        "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
        "            image_files.extend(Path(input_images_dir).glob(ext))\n",
        "\n",
        "        print(f\"Found {len(image_files)} images in {split} split\")\n",
        "        print(f\"Copying images and generating keypoint annotations...\\n\")\n",
        "\n",
        "        # Process each image\n",
        "        for img_path in tqdm(image_files, desc=f\"Processing {split}\"):\n",
        "            stats['total_images'] += 1\n",
        "\n",
        "            # Construct input label file path\n",
        "            input_label_path = os.path.join(input_labels_dir, img_path.stem + '.txt')\n",
        "\n",
        "            # Construct output paths\n",
        "            output_image_path = os.path.join(output_images_dir, img_path.name)\n",
        "            output_label_path = os.path.join(output_labels_dir, img_path.stem + '.txt')\n",
        "\n",
        "            # Copy image to output directory (using symlink would be faster but Kaggle doesn't allow it)\n",
        "            shutil.copy2(str(img_path), output_image_path)\n",
        "\n",
        "            # Load existing fighter bounding boxes\n",
        "            existing_labels = load_existing_labels(input_label_path)\n",
        "\n",
        "            if len(existing_labels) == 0:\n",
        "                # No fighters labeled, just copy the empty label file\n",
        "                if os.path.exists(input_label_path):\n",
        "                    shutil.copy2(input_label_path, output_label_path)\n",
        "                continue\n",
        "\n",
        "            # Read image to get dimensions\n",
        "            img = cv2.imread(str(img_path))\n",
        "            if img is None:\n",
        "                print(f\"⚠ Warning: Could not read {img_path}. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            img_height, img_width = img.shape[:2]\n",
        "\n",
        "            # Run pose estimation on the full image with explicit device specification\n",
        "            results = model(img, conf=pose_confidence, device=device, verbose=False)\n",
        "\n",
        "            # Extract pose detections\n",
        "            if len(results) == 0 or results[0].keypoints is None:\n",
        "                # No poses detected, save labels without keypoints\n",
        "                annotations = []\n",
        "                for fighter_label in existing_labels:\n",
        "                    annotations.append({\n",
        "                        'class_id': fighter_label[0],\n",
        "                        'bbox': fighter_label[1:5],\n",
        "                        'keypoints': None\n",
        "                    })\n",
        "                save_yolo_pose_labels(output_label_path, annotations)\n",
        "                continue\n",
        "\n",
        "            result = results[0]\n",
        "\n",
        "            # Check if we have any detections\n",
        "            if result.boxes is None or len(result.boxes) == 0:\n",
        "                # No poses detected, save labels without keypoints\n",
        "                annotations = []\n",
        "                for fighter_label in existing_labels:\n",
        "                    annotations.append({\n",
        "                        'class_id': fighter_label[0],\n",
        "                        'bbox': fighter_label[1:5],\n",
        "                        'keypoints': None\n",
        "                    })\n",
        "                save_yolo_pose_labels(output_label_path, annotations)\n",
        "                continue\n",
        "\n",
        "            stats['images_with_poses'] += 1\n",
        "\n",
        "            # Prepare annotations list (will contain bbox + keypoints for each fighter)\n",
        "            annotations = []\n",
        "            matched_fighter_indices = set()  # Track which fighters we've matched\n",
        "\n",
        "            # For each existing fighter bounding box, find the best matching pose\n",
        "            for fighter_idx, fighter_label in enumerate(existing_labels):\n",
        "                class_id = fighter_label[0]\n",
        "                fighter_bbox = fighter_label[1:5]  # [x_center, y_center, width, height] normalized\n",
        "\n",
        "                stats['total_fighters_annotated'] += 1\n",
        "\n",
        "                best_iou = 0\n",
        "                best_match_idx = -1\n",
        "\n",
        "                # Compare with all detected poses\n",
        "                for det_idx in range(len(result.boxes)):\n",
        "                    # Get detection bounding box in normalized YOLO format\n",
        "                    det_box_xyxy = result.boxes[det_idx].xyxy[0].cpu().numpy()  # [x1, y1, x2, y2] in pixels\n",
        "                    det_box_xywh = xyxy_to_xywh_normalized(det_box_xyxy, img_width, img_height)\n",
        "\n",
        "                    # Calculate IoU with fighter box\n",
        "                    iou = calculate_iou(fighter_bbox, det_box_xywh)\n",
        "\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_match_idx = det_idx\n",
        "\n",
        "                # If we found a good match, extract keypoints\n",
        "                if best_iou >= iou_threshold and best_match_idx not in matched_fighter_indices:\n",
        "                    matched_fighter_indices.add(best_match_idx)\n",
        "                    stats['fighters_matched'] += 1\n",
        "\n",
        "                    # Extract keypoints from the matched detection\n",
        "                    kps = result.keypoints[best_match_idx].data[0].cpu().numpy()  # Shape: (17, 3)\n",
        "\n",
        "                    # Normalize keypoints to 0-1 range and format for YOLO\n",
        "                    keypoints = []\n",
        "                    for kp in kps:\n",
        "                        x_norm = kp[0] / img_width\n",
        "                        y_norm = kp[1] / img_height\n",
        "                        confidence = kp[2]\n",
        "\n",
        "                        # Convert confidence to visibility flag\n",
        "                        # YOLO-Pose uses: 0=not labeled, 1=labeled but occluded, 2=labeled and visible\n",
        "                        # We'll use confidence threshold to determine visibility\n",
        "                        if confidence < 0.3:\n",
        "                            visibility = 1  # Low confidence = occluded\n",
        "                        else:\n",
        "                            visibility = 2  # High confidence = visible\n",
        "\n",
        "                        keypoints.append([x_norm, y_norm, visibility])\n",
        "\n",
        "                    annotation = {\n",
        "                        'class_id': class_id,\n",
        "                        'bbox': fighter_bbox,\n",
        "                        'keypoints': keypoints\n",
        "                    }\n",
        "                else:\n",
        "                    # No matching pose found, save without keypoints\n",
        "                    stats['fighters_unmatched'] += 1\n",
        "                    annotation = {\n",
        "                        'class_id': class_id,\n",
        "                        'bbox': fighter_bbox,\n",
        "                        'keypoints': None\n",
        "                    }\n",
        "\n",
        "                annotations.append(annotation)\n",
        "\n",
        "            # Save updated labels to output directory\n",
        "            save_yolo_pose_labels(output_label_path, annotations)\n",
        "\n",
        "            # Clear GPU cache periodically to prevent memory accumulation\n",
        "            if device_info['cuda_available'] and stats['total_images'] % 100 == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"PROCESSING COMPLETE - SUMMARY\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nTotal images processed: {stats['total_images']}\")\n",
        "    print(f\"Images with pose detections: {stats['images_with_poses']}\")\n",
        "    print(f\"Total fighters in dataset: {stats['total_fighters_annotated']}\")\n",
        "    print(f\"Fighters matched with poses: {stats['fighters_matched']} ({100*stats['fighters_matched']/max(stats['total_fighters_annotated'],1):.1f}%)\")\n",
        "    print(f\"Fighters without pose match: {stats['fighters_unmatched']} ({100*stats['fighters_unmatched']/max(stats['total_fighters_annotated'],1):.1f}%)\")\n",
        "\n",
        "    print(f\"\\n✓ Dataset augmentation complete!\")\n",
        "    print(f\"✓ New dataset with keypoint annotations saved to: {output_root}\")\n",
        "    print(f\"✓ Your labels now include keypoint annotations in YOLO-Pose format\")\n",
        "    print(f\"\\nYou can now use this dataset at '{output_root}' for YOLO-Pose training!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:35:10.489244Z",
          "iopub.execute_input": "2025-11-07T20:35:10.48955Z",
          "iopub.status.idle": "2025-11-07T20:35:10.508671Z",
          "shell.execute_reply.started": "2025-11-07T20:35:10.48953Z",
          "shell.execute_reply": "2025-11-07T20:35:10.507784Z"
        },
        "id": "cBMsqYuBJlq6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# RUN THE SCRIPT\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_dataset(\n",
        "        input_root=DATASET_INPUT,\n",
        "        output_root=DATASET_OUTPUT,\n",
        "        splits=SPLITS,\n",
        "        iou_threshold=IOU_THRESHOLD,\n",
        "        pose_confidence=POSE_CONFIDENCE,\n",
        "        device_str=DEVICE,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:35:29.405621Z",
          "iopub.execute_input": "2025-11-07T20:35:29.4063Z",
          "iopub.status.idle": "2025-11-07T20:40:17.770288Z",
          "shell.execute_reply.started": "2025-11-07T20:35:29.406272Z",
          "shell.execute_reply": "2025-11-07T20:40:17.769288Z"
        },
        "id": "y316Y-GmJlq7",
        "outputId": "b092c9b7-7236-4947-f51f-6f0aa9bdde3f",
        "colab": {
          "referenced_widgets": [
            "9cae39b3340c481d9d4bf3ebff3deb35",
            "f2755788e017404cad6ace5a8ada2989",
            "8dcb7058e55a4cb3bef1970e4320075e"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "======================================================================\nYOLO-Pose Keypoint Annotation Generator (Kaggle Version)\n======================================================================\n\nInput dataset: /kaggle/input/mma-fighter-detection-pose-estimation/mma-fighter-detection-dataset\nOutput dataset: /kaggle/working/mma-fighter-pose-dataset\nSplits to process: ['train', 'valid', 'test']\nIoU threshold: 0.6\nPose confidence: 0.3\nBatch size: 16\n\n\n======================================================================\nCOMPUTE DEVICE INFORMATION\n======================================================================\n✓ GPU acceleration ENABLED\n  Device: cuda:0\n  GPU Name: Tesla P100-PCIE-16GB\n  Total GPU Memory: 15.89 GB\n  Available GPUs: 1\n\n  This will provide 10-50x speedup compared to CPU processing!\n======================================================================\n\nLoading pretrained YOLO-Pose model...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-pose.pt to 'yolo11x-pose.pt': 100% ━━━━━━━━━━━━ 113.0MB 278.4MB/s 0.4s 0.4s<0.0s\n✓ Model loaded successfully on cuda:0!\n\nCopying data.yaml to output directory...\n✓ data.yaml copied\n\n\n======================================================================\nProcessing TRAIN split\n======================================================================\n\nFound 3635 images in train split\nCopying images and generating keypoint annotations...\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Processing train:   0%|          | 0/3635 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cae39b3340c481d9d4bf3ebff3deb35"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n======================================================================\nProcessing VALID split\n======================================================================\n\nFound 980 images in valid split\nCopying images and generating keypoint annotations...\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Processing valid:   0%|          | 0/980 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2755788e017404cad6ace5a8ada2989"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n======================================================================\nProcessing TEST split\n======================================================================\n\nFound 491 images in test split\nCopying images and generating keypoint annotations...\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Processing test:   0%|          | 0/491 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dcb7058e55a4cb3bef1970e4320075e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n======================================================================\nPROCESSING COMPLETE - SUMMARY\n======================================================================\n\nTotal images processed: 5106\nImages with pose detections: 5106\nTotal fighters in dataset: 10186\nFighters matched with poses: 10155 (99.7%)\nFighters without pose match: 31 (0.3%)\n\n✓ Dataset augmentation complete!\n✓ New dataset with keypoint annotations saved to: /kaggle/working/mma-fighter-pose-dataset\n✓ Your labels now include keypoint annotations in YOLO-Pose format\n\nYou can now use this dataset at '/kaggle/working/mma-fighter-pose-dataset' for YOLO-Pose training!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your augmented dataset\n",
        "dataset_root = \"/kaggle/working/mma-fighter-pose-dataset\"\n",
        "\n",
        "# Number of keypoints expected (17 for COCO format)\n",
        "NUM_KEYPOINTS = 17\n",
        "\n",
        "def check_label_has_keypoints(label_path):\n",
        "    \"\"\"\n",
        "    Check if a label file contains instances without keypoints.\n",
        "    Returns list of (line_number, has_keypoints) tuples.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(label_path):\n",
        "        return []\n",
        "\n",
        "    instances = []\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line_num, line in enumerate(f, 1):\n",
        "            parts = line.strip().split()\n",
        "            # Format: class_id x y w h [kp1_x kp1_y kp1_v ... kp17_x kp17_y kp17_v]\n",
        "            # With keypoints: 1 + 4 + (17 * 3) = 56 values\n",
        "            # Without keypoints: 1 + 4 = 5 values\n",
        "\n",
        "            has_keypoints = len(parts) > 5\n",
        "            instances.append((line_num, has_keypoints))\n",
        "\n",
        "    return instances\n",
        "\n",
        "# Find all images with missing keypoints\n",
        "print(\"Scanning dataset for images with missing keypoint annotations...\\n\")\n",
        "\n",
        "images_with_missing_keypoints = []\n",
        "\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    labels_dir = os.path.join(dataset_root, split, 'labels')\n",
        "    images_dir = os.path.join(dataset_root, split, 'images')\n",
        "\n",
        "    if not os.path.exists(labels_dir):\n",
        "        continue\n",
        "\n",
        "    label_files = list(Path(labels_dir).glob('*.txt'))\n",
        "\n",
        "    for label_path in label_files:\n",
        "        instances = check_label_has_keypoints(str(label_path))\n",
        "\n",
        "        # Check if any instance is missing keypoints\n",
        "        missing_count = sum(1 for _, has_kp in instances if not has_kp)\n",
        "\n",
        "        if missing_count > 0:\n",
        "            # Find corresponding image\n",
        "            img_name = label_path.stem\n",
        "            img_path = None\n",
        "            for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n",
        "                potential_img = os.path.join(images_dir, img_name + ext)\n",
        "                if os.path.exists(potential_img):\n",
        "                    img_path = potential_img\n",
        "                    break\n",
        "\n",
        "            images_with_missing_keypoints.append({\n",
        "                'split': split,\n",
        "                'image': img_path,\n",
        "                'label': str(label_path),\n",
        "                'missing_count': missing_count,\n",
        "                'total_instances': len(instances)\n",
        "            })\n",
        "\n",
        "# Print results\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"IMAGES WITH MISSING KEYPOINT ANNOTATIONS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "if len(images_with_missing_keypoints) == 0:\n",
        "    print(\"✓ All instances have keypoint annotations!\")\n",
        "else:\n",
        "    print(f\"Found {len(images_with_missing_keypoints)} images with missing keypoints:\\n\")\n",
        "\n",
        "    for idx, item in enumerate(images_with_missing_keypoints, 1):\n",
        "        print(f\"{idx}. [{item['split'].upper()}] {Path(item['image']).name}\")\n",
        "        print(f\"   Missing: {item['missing_count']}/{item['total_instances']} fighters\")\n",
        "        print(f\"   Image: {item['image']}\")\n",
        "        print(f\"   Label: {item['label']}\\n\")\n",
        "\n",
        "# Save list to file for reference\n",
        "output_file = \"/kaggle/working/images_needing_review.txt\"\n",
        "with open(output_file, 'w') as f:\n",
        "    f.write(\"Images requiring manual keypoint annotation\\n\")\n",
        "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
        "\n",
        "    for item in images_with_missing_keypoints:\n",
        "        f.write(f\"Split: {item['split']}\\n\")\n",
        "        f.write(f\"Image: {item['image']}\\n\")\n",
        "        f.write(f\"Label: {item['label']}\\n\")\n",
        "        f.write(f\"Missing: {item['missing_count']}/{item['total_instances']} fighters\\n\")\n",
        "        f.write(\"-\" * 70 + \"\\n\")\n",
        "\n",
        "print(f\"\\n✓ List saved to: {output_file}\")\n",
        "print(f\"\\nRecommendation: Review these {len(images_with_missing_keypoints)} images and manually\")\n",
        "print(f\"annotate the missing keypoints using a tool like CVAT, Labelme, or Label Studio.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T21:05:58.493268Z",
          "iopub.execute_input": "2025-11-07T21:05:58.493583Z",
          "iopub.status.idle": "2025-11-07T21:05:58.680086Z",
          "shell.execute_reply.started": "2025-11-07T21:05:58.493563Z",
          "shell.execute_reply": "2025-11-07T21:05:58.679376Z"
        },
        "id": "LS5gAn6WJlq8",
        "outputId": "02fa332a-1dfb-4b09-ca48-4662dd49a9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Scanning dataset for images with missing keypoint annotations...\n\n======================================================================\nIMAGES WITH MISSING KEYPOINT ANNOTATIONS\n======================================================================\n\nFound 31 images with missing keypoints:\n\n1. [TRAIN] 4_mp4-0201_jpg.rf.55371adca0432434f29e0ff4d0656dd1.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/4_mp4-0201_jpg.rf.55371adca0432434f29e0ff4d0656dd1.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/4_mp4-0201_jpg.rf.55371adca0432434f29e0ff4d0656dd1.txt\n\n2. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0884_jpg.rf.5cc30faf5e0358353426ad4eeca2ed28.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0884_jpg.rf.5cc30faf5e0358353426ad4eeca2ed28.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0884_jpg.rf.5cc30faf5e0358353426ad4eeca2ed28.txt\n\n3. [TRAIN] -vs-zhC7KhFk49M-_mp4-0163_jpg.rf.28f28b5c94d1676966b120ad0b75aef0.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-zhC7KhFk49M-_mp4-0163_jpg.rf.28f28b5c94d1676966b120ad0b75aef0.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-zhC7KhFk49M-_mp4-0163_jpg.rf.28f28b5c94d1676966b120ad0b75aef0.txt\n\n4. [TRAIN] 17_mp4-0027_jpg.rf.d00f5f81623e7f88529558950d6ba05b.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/17_mp4-0027_jpg.rf.d00f5f81623e7f88529558950d6ba05b.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/17_mp4-0027_jpg.rf.d00f5f81623e7f88529558950d6ba05b.txt\n\n5. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0864_jpg.rf.8c6ffd7ac4d5fef723aea6606d4816fd.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0864_jpg.rf.8c6ffd7ac4d5fef723aea6606d4816fd.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0864_jpg.rf.8c6ffd7ac4d5fef723aea6606d4816fd.txt\n\n6. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0765_jpg.rf.032278c70924e1b0d7dccfa5cead52ef.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0765_jpg.rf.032278c70924e1b0d7dccfa5cead52ef.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0765_jpg.rf.032278c70924e1b0d7dccfa5cead52ef.txt\n\n7. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0135_jpg.rf.2c3b8d7c5d89a4e4c90a1e4812fc7216.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0135_jpg.rf.2c3b8d7c5d89a4e4c90a1e4812fc7216.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0135_jpg.rf.2c3b8d7c5d89a4e4c90a1e4812fc7216.txt\n\n8. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0310_jpg.rf.43a834523096f3f6746daf690ee69ead.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0310_jpg.rf.43a834523096f3f6746daf690ee69ead.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0310_jpg.rf.43a834523096f3f6746daf690ee69ead.txt\n\n9. [TRAIN] -vs-zhC7KhFk49M-_mp4-0124_jpg.rf.88e6395f11595b11c7a57a6479b611e3.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-zhC7KhFk49M-_mp4-0124_jpg.rf.88e6395f11595b11c7a57a6479b611e3.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-zhC7KhFk49M-_mp4-0124_jpg.rf.88e6395f11595b11c7a57a6479b611e3.txt\n\n10. [TRAIN] 13_mp4-0198_jpg.rf.ae5570ffbbe2ad1d39d1d99abb40c216.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/13_mp4-0198_jpg.rf.ae5570ffbbe2ad1d39d1d99abb40c216.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/13_mp4-0198_jpg.rf.ae5570ffbbe2ad1d39d1d99abb40c216.txt\n\n11. [TRAIN] 20_mp4-0372_jpg.rf.53995e4b9fcd19d291fd646b7bcf0275.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/20_mp4-0372_jpg.rf.53995e4b9fcd19d291fd646b7bcf0275.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/20_mp4-0372_jpg.rf.53995e4b9fcd19d291fd646b7bcf0275.txt\n\n12. [TRAIN] 6_mp4-0221_jpg.rf.068eba64065bb12a37fb3303c5091fcf.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/6_mp4-0221_jpg.rf.068eba64065bb12a37fb3303c5091fcf.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/6_mp4-0221_jpg.rf.068eba64065bb12a37fb3303c5091fcf.txt\n\n13. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0771_jpg.rf.6803ec035f8857ca57bb99d228cf62dd.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0771_jpg.rf.6803ec035f8857ca57bb99d228cf62dd.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0771_jpg.rf.6803ec035f8857ca57bb99d228cf62dd.txt\n\n14. [TRAIN] -vs-zhC7KhFk49M-_mp4-0655_jpg.rf.285e296628a9dba33364e8312ece7c25.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-zhC7KhFk49M-_mp4-0655_jpg.rf.285e296628a9dba33364e8312ece7c25.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-zhC7KhFk49M-_mp4-0655_jpg.rf.285e296628a9dba33364e8312ece7c25.txt\n\n15. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0460_jpg.rf.c8864273070fdebd0b8aaee8afe1853f.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0460_jpg.rf.c8864273070fdebd0b8aaee8afe1853f.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0460_jpg.rf.c8864273070fdebd0b8aaee8afe1853f.txt\n\n16. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0438_jpg.rf.1ed45fc799a5179b2b4279f07f323898.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0438_jpg.rf.1ed45fc799a5179b2b4279f07f323898.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0438_jpg.rf.1ed45fc799a5179b2b4279f07f323898.txt\n\n17. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0129_jpg.rf.4a3993bd694c2e0e1988a54dbe088da7.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0129_jpg.rf.4a3993bd694c2e0e1988a54dbe088da7.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0129_jpg.rf.4a3993bd694c2e0e1988a54dbe088da7.txt\n\n18. [TRAIN] -vs-1-DPjtZWsn8gM-_mp4-0723_jpg.rf.bf74f2b7ce1d71cc1144564a1a12baec.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/-vs-1-DPjtZWsn8gM-_mp4-0723_jpg.rf.bf74f2b7ce1d71cc1144564a1a12baec.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/-vs-1-DPjtZWsn8gM-_mp4-0723_jpg.rf.bf74f2b7ce1d71cc1144564a1a12baec.txt\n\n19. [TRAIN] 13_mp4-0222_jpg.rf.f7a57804d5500df3e1011f1163dc9927.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/train/images/13_mp4-0222_jpg.rf.f7a57804d5500df3e1011f1163dc9927.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/train/labels/13_mp4-0222_jpg.rf.f7a57804d5500df3e1011f1163dc9927.txt\n\n20. [VALID] 17_mp4-0205_jpg.rf.b423a9b9f20a025f101158b7b7aab60e.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/valid/images/17_mp4-0205_jpg.rf.b423a9b9f20a025f101158b7b7aab60e.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/valid/labels/17_mp4-0205_jpg.rf.b423a9b9f20a025f101158b7b7aab60e.txt\n\n21. [VALID] -vs-1-DPjtZWsn8gM-_mp4-0757_jpg.rf.63dd28a1b6b4c8084bbd8d1764df6ba2.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/valid/images/-vs-1-DPjtZWsn8gM-_mp4-0757_jpg.rf.63dd28a1b6b4c8084bbd8d1764df6ba2.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/valid/labels/-vs-1-DPjtZWsn8gM-_mp4-0757_jpg.rf.63dd28a1b6b4c8084bbd8d1764df6ba2.txt\n\n22. [VALID] 14_mp4-0075_jpg.rf.e88ef73df016f4f65df5e913e3fcf8fc.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/valid/images/14_mp4-0075_jpg.rf.e88ef73df016f4f65df5e913e3fcf8fc.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/valid/labels/14_mp4-0075_jpg.rf.e88ef73df016f4f65df5e913e3fcf8fc.txt\n\n23. [VALID] 17_mp4-0204_jpg.rf.956600920443f4e7c09089555229a219.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/valid/images/17_mp4-0204_jpg.rf.956600920443f4e7c09089555229a219.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/valid/labels/17_mp4-0204_jpg.rf.956600920443f4e7c09089555229a219.txt\n\n24. [VALID] -vs-1-DPjtZWsn8gM-_mp4-0926_jpg.rf.4e98988ebdc8fbc7ad1134f9cbd560e5.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/valid/images/-vs-1-DPjtZWsn8gM-_mp4-0926_jpg.rf.4e98988ebdc8fbc7ad1134f9cbd560e5.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/valid/labels/-vs-1-DPjtZWsn8gM-_mp4-0926_jpg.rf.4e98988ebdc8fbc7ad1134f9cbd560e5.txt\n\n25. [VALID] -vs-1-DPjtZWsn8gM-_mp4-0619_jpg.rf.74e7e6fe7134384e97778d86ebabf080.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/valid/images/-vs-1-DPjtZWsn8gM-_mp4-0619_jpg.rf.74e7e6fe7134384e97778d86ebabf080.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/valid/labels/-vs-1-DPjtZWsn8gM-_mp4-0619_jpg.rf.74e7e6fe7134384e97778d86ebabf080.txt\n\n26. [VALID] 12_mp4-0162_jpg.rf.1bb89e1be8c9a25a02cb473700f585f9.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/valid/images/12_mp4-0162_jpg.rf.1bb89e1be8c9a25a02cb473700f585f9.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/valid/labels/12_mp4-0162_jpg.rf.1bb89e1be8c9a25a02cb473700f585f9.txt\n\n27. [VALID] -vs-1-DPjtZWsn8gM-_mp4-0621_jpg.rf.63574f0e27cc288f05603f8e6972f940.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/valid/images/-vs-1-DPjtZWsn8gM-_mp4-0621_jpg.rf.63574f0e27cc288f05603f8e6972f940.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/valid/labels/-vs-1-DPjtZWsn8gM-_mp4-0621_jpg.rf.63574f0e27cc288f05603f8e6972f940.txt\n\n28. [VALID] 17_mp4-0171_jpg.rf.cd86aebc9f0eaa4938fc8d91843a297b.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/valid/images/17_mp4-0171_jpg.rf.cd86aebc9f0eaa4938fc8d91843a297b.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/valid/labels/17_mp4-0171_jpg.rf.cd86aebc9f0eaa4938fc8d91843a297b.txt\n\n29. [TEST] 7_mp4-0416_jpg.rf.b8183aaf9d7f689f4e3991e6f2eb2895.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/test/images/7_mp4-0416_jpg.rf.b8183aaf9d7f689f4e3991e6f2eb2895.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/test/labels/7_mp4-0416_jpg.rf.b8183aaf9d7f689f4e3991e6f2eb2895.txt\n\n30. [TEST] -vs-zhC7KhFk49M-_mp4-0693_jpg.rf.0125531aac4b4efc35e276f0cbf6748f.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/test/images/-vs-zhC7KhFk49M-_mp4-0693_jpg.rf.0125531aac4b4efc35e276f0cbf6748f.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/test/labels/-vs-zhC7KhFk49M-_mp4-0693_jpg.rf.0125531aac4b4efc35e276f0cbf6748f.txt\n\n31. [TEST] -vs-1-DPjtZWsn8gM-_mp4-0775_jpg.rf.4d3beec900cdedd45ab7f97e80a08c73.jpg\n   Missing: 1/2 fighters\n   Image: /kaggle/working/mma-fighter-pose-dataset/test/images/-vs-1-DPjtZWsn8gM-_mp4-0775_jpg.rf.4d3beec900cdedd45ab7f97e80a08c73.jpg\n   Label: /kaggle/working/mma-fighter-pose-dataset/test/labels/-vs-1-DPjtZWsn8gM-_mp4-0775_jpg.rf.4d3beec900cdedd45ab7f97e80a08c73.txt\n\n\n✓ List saved to: /kaggle/working/images_needing_review.txt\n\nRecommendation: Review these 31 images and manually\nannotate the missing keypoints using a tool like CVAT, Labelme, or Label Studio.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Path to your augmented dataset\n",
        "dataset_path = \"/kaggle/working/mma-fighter-pose-dataset\"\n",
        "\n",
        "# Create a ZIP archive\n",
        "print(\"Creating ZIP archive of your augmented dataset...\")\n",
        "print(\"This may take a few minutes depending on dataset size...\")\n",
        "\n",
        "archive_path = \"/kaggle/working/mma-fighter-pose-dataset\"\n",
        "shutil.make_archive(archive_path, 'zip', dataset_path)\n",
        "\n",
        "archive_file = archive_path + '.zip'\n",
        "archive_size_mb = os.path.getsize(archive_file) / (1024 * 1024)\n",
        "\n",
        "print(f\"\\n✓ Archive created successfully!\")\n",
        "print(f\"  File: {archive_file}\")\n",
        "print(f\"  Size: {archive_size_mb:.2f} MB\")\n",
        "print(f\"\\nTo download:\")\n",
        "print(f\"  1. Look at the right sidebar in your Kaggle notebook\")\n",
        "print(f\"  2. Click on 'Output' tab\")\n",
        "print(f\"  3. You'll see 'mma-fighter-pose-dataset.zip'\")\n",
        "print(f\"  4. Click the download icon next to it\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T20:43:06.54791Z",
          "iopub.execute_input": "2025-11-07T20:43:06.548709Z",
          "iopub.status.idle": "2025-11-07T20:43:15.58234Z",
          "shell.execute_reply.started": "2025-11-07T20:43:06.54868Z",
          "shell.execute_reply": "2025-11-07T20:43:15.58171Z"
        },
        "id": "Sk_-wBdSJlq9",
        "outputId": "8a6ffce1-7bfb-445d-bcb9-478884d6e6e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Creating ZIP archive of your augmented dataset...\nThis may take a few minutes depending on dataset size...\n\n✓ Archive created successfully!\n  File: /kaggle/working/mma-fighter-pose-dataset.zip\n  Size: 275.55 MB\n\nTo download:\n  1. Look at the right sidebar in your Kaggle notebook\n  2. Click on 'Output' tab\n  3. You'll see 'mma-fighter-pose-dataset.zip'\n  4. Click the download icon next to it\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "e3N_AIDuJlq9"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}